\section*{Probability Terminology}

\textbf{Random experiment}: action with \textit{uncertain} outcome.

\textbf{Sample space} $\Omega$:
\begin{equation*}
    \Omega = \set{ \text{all possible outcomes} }
\end{equation*}

\textbf{Event} or \textbf{Event Space} $E$:
\begin{equation*}
    E \subseteq \Omega
\end{equation*}

\textbf{Complement Event} $\AbsComplement{E}$:

Event $\AbsComplement{E}$ is the event that $E$ does \textit{not} occur.
\begin{equation*}
    \AbsComplement{E} = \set{ \omega \in \Omega \given \omega \not\in E }
\end{equation*}

\textbf{Intersection of Events} $E_1 \cap E_2$:

$E_1 \cap E_2$ is event that $E_1$ and $E_2$ occurring \textit{together}.
\begin{equation*}
    E_1 \cap E_2 = \set{ \omega \in \Omega \given \omega \in E_1 \land \omega \in E_2 }
\end{equation*}

\textbf{Union of Events} $E_1 \cup E_2$:

$E_1 \cup E_2$ is the event that $E_1$ \textit{or} $E_2$ occurring or \textit{both}.
\begin{equation*}
    E_1 \cup E_2 = \set{ \omega \in \Omega \given \omega \in E_1 \lor \omega \in E_2 }
\end{equation*}

\textbf{Difference} $E_1 \setminus E_2$:

$E_1 \setminus E_2$ is the event that $E_1$ \textit{occurs} but \textit{not} $E_2$.
\begin{equation*}
    E_1 \setminus E_2 = \set{ \omega \in \Omega \given \omega \in E_1 \land \omega \not\in E_2 }
\end{equation*}

\textbf{Useful Identities}:
\begin{align*}
    \AbsComplement{A \cap B} &= \AbsComplement{A} \cup \AbsComplement{B} \\
    \AbsComplement{A \cup B} &= \AbsComplement{A} \cap \AbsComplement{B} \\
    A \cap (B \cup C) &= (A \cap B) \cup (A \cap C) \\
    A \cup (B \cap C) &= (A \cup B) \cap (A \cup C)
\end{align*}

\textbf{Disjoint} or \textbf{Mutually Exclusive} $E_1 \xor E_2$:

Given events $E_1$ and $E_2$ then they are \textit{disjoint} or \textit{mutually exclusive} iff:
\begin{equation*}
    E_1 \cap E_2 = \varnothing \iff E_1 \xor E_2
\end{equation*}

That is $E_1$ and $E_2$ \textit{cannot both occur}.

\textbf{Probability of an Event} $\Prob{E}$: \textit{proportion} of times that event $E$ is expected to occur in a large sample size.

\section*{Probability Properties}

\begin{gather*}
    \begin{aligned}
        \Prob{E} &\ge 0 \\
        \Prob{E} &\le 1 \\
        \Prob{\Omega} &= 1 \\
        \Prob{\varnothing} &= 0
    \end{aligned} \\
    \Prob{E_1 \cup E_2} = \Prob{E_1} + \Prob{E_2} - \Prob{E_1 \cap E_2}
\end{gather*}

\begin{equation*}
    E_1 \xor E_2 \iff \Prob{E_1 \cap E_2} = \Prob{E_1} + \Prob{E_2}
\end{equation*}

\section*{Probability Definition}

A \textbf{probability measure} $\mathrm{P} \colon E \to \Real$ associates each \textit{event} $E$ with a probability $\Prob{E}$ such that the three properties are satisfied:

\begin{enumerate}
    \item \textbf{Non-negative}:
    \begin{equation*}
        \Forall E \colon \Prob{E} \ge 0
    \end{equation*}
    \item \textbf{Sums to} $1$:
    \begin{equation*}
        \Prob{\Omega} = 1
    \end{equation*}
    \item \textbf{Countable additivity}: given \textit{events} $E_1, \dots, E_n$ such that each event is \textit{independent} from all other event:
    \begin{equation*}
        \Forall i, j \in [1, n] \colon i \ne j \to E_i \cap E_j = \varnothing
    \end{equation*}
    Then
    \begin{equation*}
        \Prob{E_1 \cup \cdots \cup E_n} = \Prob{E_1} + \cdots + \Prob{E_n}
    \end{equation*}
\end{enumerate}

\section*{Combinatorical Probability}

If all outcomes for a random experiment are \textit{equally} likely, then the probability of event $E$ is
\begin{equation*}
    \Prob{E} = \frac{ \mathrm{n}(E) }{ \mathrm{n}(\Omega) }
\end{equation*}
